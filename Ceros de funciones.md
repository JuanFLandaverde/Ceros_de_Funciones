# Fundamentos Te√≥ricos de M√©todos Num√©ricos

Este archivo contiene una descripci√≥n breve y te√≥rica de los m√©todos num√©ricos implementados en este repositorio, enfocados en la soluci√≥n de ecuaciones no lineales de la forma:

$$
f(x) = 0
$$

## üìê 1. M√©todo de Bisecci√≥n

Es un m√©todo **cerrado** que requiere que la funci√≥n $$f(x)$$ sea continua en el intervalo $$[a, b]$$ y que se cumpla $$f(a) \cdot f(b) < 0$$ (cambio de signo).

**Idea**: En cada iteraci√≥n se divide el intervalo a la mitad y se selecciona el subintervalo donde persiste el cambio de signo.

- Convergencia: **lineal**  
- Ventajas: siempre converge si se cumplen las condiciones  
- Desventajas: lento en comparaci√≥n con otros m√©todos

---

## üìâ 2. M√©todo de Newton-Raphson

Es un m√©todo **abierto** que usa la derivada de la funci√≥n para aproximar la ra√≠z:

$$
x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}
$$

**Requiere** una estimaci√≥n inicial $$x_0$$ y que $$f'(x) \neq 0$$ cerca de la ra√≠z.

- Convergencia: **cuadr√°tica** (cuando converge)  
- Ventajas: muy r√°pido si se tiene buena aproximaci√≥n inicial  
- Desventajas: puede divergir si $$f'(x)$$ se anula o es muy peque√±a

---

## üìà 3. M√©todo de la Secante

Similar a Newton-Raphson, pero no requiere la derivada. Usa una aproximaci√≥n con diferencias finitas:

$$
x_{n+1} = x_n - f(x_n) \cdot \frac{x_n - x_{n-1}}{f(x_n) - f(x_{n-1})}
$$

- Convergencia: **superlineal** ($$\approx 1.618$$)  
- Ventajas: no necesita derivada  
- Desventajas: requiere dos estimaciones iniciales

---

## ‚öñÔ∏è 4. M√©todo de Regula-Falsi (Falsa Posici√≥n)

Es un m√©todo **cerrado** como la bisecci√≥n, pero en lugar de usar el punto medio del intervalo, calcula el punto donde la l√≠nea secante entre $$f(a)$$ y $$f(b)$$ corta el eje $$x$$.

La f√≥rmula para encontrar la siguiente aproximaci√≥n $$x_r$$ es:

$$
x_r = b - \frac{f(b)(a - b)}{f(a) - f(b)}
$$

Luego se eval√∫a el signo de $$f(x_r) \cdot f(a)$$ para decidir el nuevo intervalo, igual que en la bisecci√≥n.

- Convergencia: **lineal** (m√°s r√°pida que bisecci√≥n en muchos casos)  
- Ventajas: m√°s eficiente que la bisecci√≥n  
- Desventajas: puede estancarse si uno de los extremos no se actualiza (problema de "anclaje")

---

## üîÅ 5. M√©todo de Punto Fijo

Reescribe la ecuaci√≥n original como $$x = g(x)$$, y se itera:

$$
x_{n+1} = g(x_n)
$$

Para que el m√©todo converja, la funci√≥n $$g(x)$$ debe cumplir:

- Ser continua  
- $$|g'(x)| < 1$$ en el intervalo

- Convergencia: **lineal**  
- Ventajas: simple de implementar  
- Desventajas: depende fuertemente de la elecci√≥n de $$g(x)$$


---
## ‚ö° 6. Aceleraci√≥n de Aitken (Œî¬≤)

Mejora la convergencia de m√©todos iterativos lineales como el de punto fijo, aplicando la f√≥rmula:

$$
x^* \approx x_n - \frac{(x_{n+1} - x_n)^2}{x_{n+2} - 2x_{n+1} + x_n}
$$

- Convergencia: m√°s r√°pida  
- Requiere tres iteraciones sucesivas

---

## ‚öôÔ∏è 7. M√©todo de Steffensen

Evita el uso de derivadas como Newton, aplicando una t√©cnica similar a Aitken pero internamente:

$$
x_{n+1} = x_n - \frac{[g(x_n) - x_n]^2}{g(g(x_n)) - 2g(x_n) + x_n}
$$

- No necesita derivadas  
- Convergencia: **cuadr√°tica**

---

## üßÆ 8. M√©todo de Horner

Optimiza la evaluaci√≥n de polinomios y su derivada:

Dado un polinomio:

$$
P(x) = a_nx^n + a_{n-1}x^{n-1} + \dots + a_0
$$

Horner lo reescribe como:

$$
P(x) = (\dots((a_nx + a_{n-1})x + a_{n-2})x + \dots ) + a_0
$$

- Menor complejidad computacional  
- Utilizado en combinaci√≥n con Newton para ra√≠ces de polinomios

---

## üîé 9. M√©todo de M√ºller

Extiende la secante usando una par√°bola para interpolar tres puntos $$x_{n}, x_{n-1}, x_{n-2}$$. Resuelve la ecuaci√≥n cuadr√°tica que pasa por ellos para estimar la ra√≠z.

- Puede encontrar ra√≠ces **complejas**
- Convergencia: **superlineal**
- No requiere derivadas

---

## üìä 6. An√°lisis de Convergencia

Durante la ejecuci√≥n de algunos m√©todos (como Newton y Secante), se guarda el error relativo en cada iteraci√≥n:

$$
e_n = |x_n - x^*|
$$

La **orden de convergencia** $$p$$ se estima emp√≠ricamente usando regresi√≥n lineal log-log sobre la relaci√≥n:

$$
\log(e_{n+1}) = \log(C) + p \log(e_n)
$$

donde $$C$$ es la constante de convergencia.

---


